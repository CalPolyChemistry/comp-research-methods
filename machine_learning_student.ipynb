{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Building a Machine Learning Model to Predict Solubility\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<h2>Overview</h2>\n",
    "\n",
    "<strong>Questions:</strong>\n",
    "\n",
    "* What is machine learning?\n",
    "\n",
    "* How do machine learning models make predictions?\n",
    "\n",
    "<strong>Objectives:</strong>\n",
    "\n",
    "* Generate a cheminformatics data set using the RDKit library starting from a list of SMILES codes\n",
    "* Create and train a random forest regression model and compare the performance to a linear regression model\n",
    "* Create and train a random forest classification model\n",
    "* Generate novel cheminformatics data to use in training a random forest classification  model\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries\n",
    "We will be using many libraries for today's lesson.  Be sure to run the cell below to import all necessary libraries.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T16:51:46.314577Z",
     "start_time": "2024-06-26T16:51:46.301095Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd                 # for data manipulation\n",
    "import seaborn as sns               # for data visualization\n",
    "import matplotlib.pyplot as plt     # for data visualization\n",
    "import numpy as np                  # for numerical operations\n",
    "import sweetviz as sv               # for fast exploratory data analysis (eda)\n",
    "\n",
    "from rdkit import Chem              # for calculating cheminformatics properties of molecules\n",
    "from rdkit.Chem import Descriptors  # for determining chemical descriptors\n",
    "from rdkit.Chem import Crippen      # for calculating logP (cLogP)\n",
    "from rdkit.Chem import PandasTools  # for displaying molecules\n",
    "PandasTools.RenderImagesInAllDataFrames(images=True) # Ensures molecules are rendered in the notebook\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler                             # for scaling the data\n",
    "from sklearn.model_selection import train_test_split                         # for splitting the data into training and testing sets\n",
    "from sklearn.model_selection import cross_val_score, KFold                   # for K-fold cross-validation\n",
    "from sklearn.linear_model import LinearRegression                            # for creating a linear regression model\n",
    "from sklearn.ensemble import RandomForestRegressor                           # for creating a random forest regression model\n",
    "from sklearn.dummy import DummyRegressor                                     # for creating a base regressor to compare the model with\n",
    "from sklearn.ensemble import RandomForestClassifier                          # for creating a random forest classification model\n",
    "from sklearn.metrics import mean_squared_error, r2_score                     # for evaluating the regression model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score    # for evaluating the classification model\n",
    "from sklearn.pipeline import make_pipeline                                   # for building operational pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Solubility in Water\n",
    "\n",
    "We will be combining the skills we learned in the RDKit lesson and the pandas and seaborn lesson to  **create a cheminformatics data set** from a machine-readable list of molecules. The goal is to use the provided molecules to calculate various chemical properties of each molecule and then predict the solubility of a molecule in water based on its chemical structure and properties using machine learning models. We will create a version of the [Delaney's solubility dataset](https://doi.org/10.1021/ci034243x).  We will then use this data set to build different types of machine learning models, including linear regression modles and random forest models.  \n",
    "\n",
    "We will begin by creating a pandas dataset of molecules and their solubility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T16:49:13.095479Z",
     "start_time": "2024-06-26T16:49:13.088117Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to the list of molecules data file\n",
    "data_path = \"data/solubility-molecule-list.csv\"\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains the following columns:\n",
    "- **Compound ID**: compound name in a range of formats\n",
    "- **smiles**: SMILES string representation of each molecule\n",
    "- **logS**: the solubility of the molecule in mol/L measured at 25 $\\degree$ ùê∂ on a log scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding molecule objects to the data set using the SMILES strings\n",
    "\n",
    "We already learned out to create RDKit molecule objects from SMILES strings in our prior lessons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The `.apply` function\n",
    "\n",
    "When we are working with a lot of molecular data, we might have a whole column of SMILES strings that we need to use to make molecule objects.  Further, we would like to save those molecule objects as a new column in our pandas dataframe.  This is generally true; you often want to calculate a new column of data using an existing column in your data frame.  The way to accomplish this is to use the `.apply` method.  You access any exisiting column of your python dataframe, put `.apply()` and then in the parenthesis, give a python function that calculates the thing you want to calculate.  In the code below, we will take the column of SMILES strings and apply the `Chem.MolFromSmiles` function and save the results as a new column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing all the molecules in our data set\n",
    "df['mol'] = df['smiles'].apply(Chem.MolFromSmiles)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties that affect solubility\n",
    "As know from our prior lessons, RDKit molecule objects have a number of methods we can use to get more information about the molecule.  We are interested in creating a dataset that includes molecular properties that affect solubility, since we ultimately want to use those properties to predict the solubility of molecules.  Molecular properties we want to add to our data set include:\n",
    "1. Molecular weight\n",
    "2. The number of rotatable bonds\n",
    "3. The Wildman-Crippen LogP value, which is a measure of hydrophobicity.  It describes a molecule's preference for an organic (lipophilic) phase versus an aqueous (hydrophilic) phase phase.\n",
    "4. The aromatic ratio, which is defined as the number of heavy (non-hydrogen) aromatic atoms divided by the total number of heavy atoms.  \n",
    "   \n",
    "We can use the `.apply` function we learned about in our prior lessons to apply methods to our molecule objects and save the results in a new column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h3>Exercise</h3>\n",
    "\n",
    "For each property listed below, calculate the value of the property for every molecule in our dataset.  Add each property to your pandas dataframe as a new column.\n",
    "1. Molecular weight (`Descriptors.MolWt`)\n",
    "2. Number rotatable bonds (`Chem.rdMolDescriptors.CalcNumRotatableBonds`)\n",
    "3. The LogP value (`Chem.Crippen.MolLogP`)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating aromatic ratio\n",
    "\n",
    "The final property we want for our dataset is the aromatic ratio.  Although there is not a function in RDKit that calculates this directly, we can calculate it by creating our own function that uses two existing RDKit functions to perform the calculation. Then we can use our new function and ``.apply`` to make a new column in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T16:49:45.746932Z",
     "start_time": "2024-06-26T16:49:45.735372Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## defining the function that will calculate the aromatic proportion\n",
    "\n",
    "def aromatic_calc(mol):\n",
    "    prop_aromatic = len(mol.GetAromaticAtoms())/mol.GetNumAtoms()\n",
    "    return prop_aromatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding to the dataset\n",
    "df['aromatic_ratio'] =df['mol'].apply(aromatic_calc)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating solubility in water (g per 100 mL)\n",
    "\n",
    "Although logS is one way to describe solubility, another common definition in  applications such as water purification is grams of compound soluble in 100 mL of water. Because we already have both logS and the molecular weight for each compound, it is straightforward to calculate the solublity value as g / 100 mL of water. We will achieve this with 3 calculations in one: (1) convert logS to mol/L, (2) use molecular weight to convert this to g / L, and (3) convert to g / 100 mL of water.\n",
    "\n",
    "$$\n",
    "Solubility \\frac{g}{ 100 mL} = 10^{logS} \\hspace{2mm} \\frac{mole}{L} \\hspace{5mm} {\\rm x} \\hspace{5mm} Molecular Weight \\hspace{2mm} \\frac{g}{mole} \\hspace{5mm} {\\rm x} \\hspace{5mm} \\frac{1 L}{ 10 x 100 mL} \n",
    "$$\n",
    "\n",
    "### Defining molecules as insoluble or soluble in water.\n",
    "A common working definition for \"water soluble\" is having a solubility greater than 1 g per 100 mL. After calculating\n",
    "solubility, we will assign each compound a value of \"0\" for not soluble in water or \"1\" for soluble in water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert logS (mol/L) to g/100 mL\n",
    "df[\"solubility\"] = (10 ** df[\"logS\"] * df[\"mol_weight\"]) / 10\n",
    "\n",
    "# Binary classification\n",
    "df[\"soluble\"] = (df[\"solubility\"] > 1.0).astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other calculations RDKit can perform\n",
    "\n",
    "There are many other properties of molecules that RDKit can caculate.  In general, the methods in RDKit are organized into modules baesd on the type of property they calculate.  For instance, in some of the examples above, we used methods from the \n",
    "[`Descriptors` module](https://www.rdkit.org/docs/source/rdkit.Chem.Descriptors.html) and the [`rdMolDescriptors` module](https://www.rdkit.org/docs/source/rdkit.Chem.rdMolDescriptors.html).  You can click on either of those links to see the full list of the different properties you can access. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA) of the data set\n",
    "\n",
    "The first step in building a machine learning model, after deciding what we want to predict, is to perform exploratory data analysis (EDA) on raw data. The EDA is crucial for data preprocessing pipelines as it helps us understand the nature of our data, identify the key patterns and relationships, and detect anomalies. The EDA involves summarizing the main characteristics of the data, often using visual methods. \n",
    "\n",
    "Loading the data into a Pandas DataFrame provides a convenient way to perform EDA.  We will use SweetViz, an EDA library, to verify the data we generated has no missing values and has the expected value distributions.  The molecule images, however, will cause an error. So we will create a version of the DataFrame called df_nomol with the 'mol' column dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T16:50:52.798960Z",
     "start_time": "2024-06-26T16:50:52.792664Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropping the mol columns\n",
    "\n",
    "df_nomol = df.drop(columns = ['mol'])\n",
    "df_nomol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse Dataset\n",
    "report = sv.analyze(df_nomol)\n",
    "\n",
    "# View and Save\n",
    "report.show_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Metrics to Consider in EDA\n",
    "\n",
    "#### Checking for Missing Values\n",
    "\n",
    "Since the data is already preprocessed, the number of Missing values for all features should be zero. The experimentally measured solubility in the last column logS is the target variable and the remaining columns are the features.\n",
    "\n",
    "#### Statistical Summary of the Data\n",
    "We also see a statistical summary of each numerical features in our dataset. The provided statistics include the value counts, mean, standard deviation, minimum, 25th percentile, median, average, 75th percentile, and maximum values for each feature.\n",
    "\n",
    "This information is extremely useful for understanding the data and the distribution of the features. It helps in identifying anomalies in the data or if our data requires any preprocessing. \n",
    "\n",
    "#### Balance in the data\n",
    "For categorical variables such as soluble, model  performance is best when each class (insoluble versus soluble) is represented equally. But unbalanced data is common in real-world data sets. Models often favor predicting the majority class as statistically this produces the \"best\" results. The minority class(es) are also usually important and so attention must be paid to building models that predict all classes well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation of Features with Target Variable\n",
    "The correlation matrix between the features and the target variable provides insights into the relationships between the features and the target variable(s). You may need to click on the \"Associations\" button in order to see the correlation matrix.\n",
    "\n",
    "A correlation value close to 1 indicates a strong positive relationship, while a correlation value close to -1 indicates a strong negative relationship. A correlation value close to 0 indicates no relationship between the features.\n",
    "\n",
    "The coloring scheme makes it easy to uncover the relationships between the features. The darker the color, the stronger the correlation. The diagonal line represents the correlation of each feature with itself, which is always 1. The blue color indicates a positive correlation, while the red color signifies a negative correlation (based on the provided key)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h3>Exercise</h3>\n",
    "    If you haven't already, click on the Associations button to display the correlation plot.  <br><br>\n",
    "    Based on the correlation plot, which feature is most strongly correlated with the logS value? And is it a negative or positive correlation?\n",
    "    <br><br>\n",
    "    We calculated the solubility value using the logS value. Would you expect these values to be highly correlated?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data Into Training and Testing Sets for predicting logS\n",
    "\n",
    "Once we have a good understanding of the data, we can move on to the next step, which is splitting the data into a training set and a testing set. The training set is used to train the model, and the testing set is used to evaluate the model's performance. This process allows you to test the model's accuracy on unseen data and ensures that the model can generalize well to new data.\n",
    "\n",
    "It is extremely important to split the data first and then perform subsequent feature engineering steps such as creating new features, transforming data formats, selecting the most useful features and addressing any missing value. Feature engineering prior to splitting the data can cause a <b>data leakage</b> problem, allowing the model to \"see\" the testing data in the training phase. This violates our intention to treat the test data as a good representative sample of the real-world data. Data leakage leads to a model that performs well in training and testing but that performs poorly when given novel data.\n",
    "\n",
    "There are some columns we will need to remove from the dataframe we generated if we are predicting logS. Since the <b>solubility</b> column is a calculation based directly on logS, using it to predict logS would be equivalent to  providing logS to the model for predicting logS. The model would be very good at predicting the values, but would not be able to predict well for data outside of the original data set. This is also true for the <b>soluble</b> column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our training and testing data sets, we will use the ``train_test_split`` function from the ``sklearn.model_selection`` module to split the data. The training set will be used to train the model, while the testing set will be used to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful information about the train test split process:\n",
    "- ``x`` generally denotes the input variables (the data the model will use to make predictions)\n",
    "- ``y`` is often used for target variable (what we are trying to predict)\n",
    "- ``test_size`` is used to assign the percentage of the data set aside for the testing set\n",
    "- ``random_state`` controls the random number generator used to shuffle the data before splitting it. In other words, it ensures that the same randomization is used each time you run the code, resulting in the same splits of the data. This is especially useful if you want to compare the performance of multiple models. Note that although a random state makes it easy to compare models, it also biases how the data is handled while training the model. A best practice is to set a random state when comparing models, but to not use a random state for a model that is going into production. You can use any value for the random state, with common values being 1 or 42 (which means any AI-assistance with coding will often use 1 or 42 even if a random state does not need to be set).\n",
    "- ``shuffle = True`` ensures that the data is split randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature matrix (X), feature vector (x), and the target vector (y)\n",
    "X = df.drop(columns=['logS','solubility', 'soluble'])\n",
    "\n",
    "# We are going to start by picking just one feature, our most highly correlated thing\n",
    "x = X[\"clogP\"]\n",
    "y = df['logS']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=123, shuffle=True)\n",
    "\n",
    "# Reshape the data into 2D arrays of shape (n_samples, 1)\n",
    "# (if working with only one input feature)\n",
    "x_train = x_train.values.reshape(-1,1)\n",
    "x_test = x_test.values.reshape(-1,1)\n",
    "y_train = y_train.values.reshape(-1,1)\n",
    "y_test = y_test.values.reshape(-1,1)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note</b>\n",
    "    Note the use of the <b>x</b> vector in the <b>train_test_split</b> function as initially we will train a model using only one input feature.<br> If we instead want to use all the available features we would need to use the <b>X</b> matrix that we have defined.  This is something we will use later.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Once we have a good understanding of the data, we can move on to the next step, which is feature engineering. Feature engineering is the process of transforming the raw data into a format that is suitable for machine learning models. Feature engineering often involves creating new features, selecting the most important features, and transforming the existing features in order to improve the model's performance.\n",
    "\n",
    "After splitting our data, we need to scale our train and test features. Scaling is a crucial step in the data preprocessing pipeline as it ensures that all features have the same scale, since many machine learning models are sensitive to the scale of the input features. For example, in our dataset the values for the number of rotatable bonds ranges from 0 to 23 while the molecular weight values go as high as 781. If we left these data with these ranges, the molecular weight values would impact the final predictions more than the rotatable bonds, even if that was not the best feature to weight heavily for the prediction. Converting the data to a single standard scale is a required step, with common transformations adjusting all the data to a range between 0 and 1 or between -1 and 1. We will use the ``StandardScaler`` from the ``sklearn.preprocessing`` module to scale our features. ``StandardScaler`` transforms the data in such a manner that it has mean value of 0 and a standard deviation value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the standard scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training feature vector x_train\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# Transform the test feature vector x_test\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Make sure the training data is scaled correctly\n",
    "print(f\" Training feature mean: {x_train_scaled.mean():.5f}\")\n",
    "print(f\" Training feature standard deviation: {x_train_scaled.std():.5f}\\n\")\n",
    "\n",
    "# Print the scaler statistics on the test data\n",
    "print(f\" Testing feature mean: {x_test_scaled.mean():.5f}\")\n",
    "print(f\" Testing feature standard deviation: {x_test_scaled.std():.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Reminder:</b>\n",
    "    It is extremely important to split the data first and then fit the scaler on the training data, only. Fitting the scaler on the entire data and then splitting it causes the <b>data leakage</b> problem which violates our intention to treat the test data as a good representative sample of the real-world data.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Training a Linear Regression Model\n",
    "\n",
    "The next step after the data preparation is to build and train our model. We will build a simple linear regression model which focuses on the relationship between a single feature (``cLogP``) and the target variable (``logS``). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h3>Discussion</h3>\n",
    "    What is the reason behind choosing <b>cLogP</b> as our main feature in the linear regression model?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Judging Model Performance with a Dummy Regressor\n",
    "\n",
    "In order to evaluate the performance of our model, we can first create a dummy \"model\" using the ``DummyRegressor`` class from the ``sklearn.dummy`` module. This class provides a simple way to create a model that calculates the mean value of the target feature and predicts this mean value for each observation. The ``fit`` method is used to train the model on the training data. Once the model is trained, we can use the ``predict`` method to make predictions on the test data. Note that the ``DummyRegressor`` is not for solving real problems! The value of the ``DummyRegressor`` is to provide a baseline set of values for the evaluating the error (such as mean squared error or R-squared). An true machine learning model trained with the same data should have much better performance than the ``DummyRegressor``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy model using the mean value of the target property\n",
    "dummy_model = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "# Fit the model to the training data\n",
    "dummy_model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_dummy = dummy_model.predict(x_test_scaled)\n",
    "\n",
    "# Calculate the performance metrics and store them in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"Coefficients\": [np.array(dummy_model.constant_)],   # the regression coefficient\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred_dummy),     # the mean squared error\n",
    "    \"R2\": r2_score(y_test, y_pred_dummy)                 # the coefficient of determination\n",
    "}, index=[\"Dummy\"])\n",
    "                            \n",
    "\n",
    "# Set the formatting style\n",
    "results.style.format(\n",
    "    {\n",
    "        \"MSE\": \"{:.3f}\",\n",
    "        \"R2\": \"{:.2f}\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h3>Discussion</h3>\n",
    "    Do we want to maximize or minimize the MSE value? What about R2? \n",
    "   <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model\n",
    "\n",
    "Now let's build and train our single-feature input linear regression model.  We will use the ``LinearRegression`` class from the ``sklearn.linear_model`` module to create the model.   We already selected `cLogP` for our one feature and `logS` for our target variable when we did the test train split above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple linear regression model\n",
    "simple_reg_model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "simple_reg_model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_simple = simple_reg_model.predict(x_test_scaled)\n",
    "\n",
    "# Calculate the performance metrics\n",
    "simple_model_results = pd.DataFrame({\n",
    "    \"Coefficients\": [np.array(simple_reg_model.coef_)],   # the regression coefficient\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred_simple),     # the mean squared error\n",
    "    \"R2\": r2_score(y_test, y_pred_simple)                 # the coefficient of determination\n",
    "}, index=[\"Simple-Linear-Regression\"])\n",
    "\n",
    "# Store the results into results DataFrame\n",
    "results = pd.concat([results, simple_model_results])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h3>Discussion</h3>\n",
    "    Which model is best at predicting the value of logS? Make sure to use the relevant metrics for your evaluation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Model Performance\n",
    "\n",
    "We are now going to make a graph with matplotlib to visualize our model's performance.  We will plot the test data as blue dots, the dummy regressor as a green line, and the linear regression as a red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot object \n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Plot the test data\n",
    "ax.scatter(x_test_scaled, y_test, color='blue', label='Test Data')\n",
    "\n",
    "# Plot the simple linear regression model\n",
    "ax.plot(x_test_scaled, y_pred_simple, color='red', label='Simple Linear Regression')\n",
    "\n",
    "# Plot the baseline model\n",
    "ax.plot(x_test_scaled, y_pred_dummy, \"g--\", label=\"Dummy\")\n",
    "\n",
    "# Create the legends\n",
    "fig.legend(facecolor='white')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a multifeature linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data\n",
    "\n",
    "Using the ``cLogP`` feature with highest correlation with the target variable ``logS`` is a good starting point. However, we can improve our model by including other features that show some correlation with the target variable.  This is the idea of a multi-linear regression.\n",
    "\n",
    "Let's build a multiple linear regression model using all the features in our dataset. The process is very similar to building a single-feature linear regression model: Once again, we need to scale the data, train the model on the scaled training data using the ``fit`` method, and make predictions on the test data using the ``predict`` function.\n",
    "\n",
    "We will again split the data into train and test prior to doing any other data cleaning or engineering, to prevent data leakage between the training and testing data. We will use the ``train_test_split`` function from the ``sklearn.model_selection`` module to split the data into training and testing sets. The training set will be used to train the model, while the testing set will be used to evaluate the model's performance. We will also use a ``random_state `` again, so the data is the same when comparing different models. \n",
    "\n",
    "We will drop the target vector 'logS', and also the 'smiles', 'mol', 'Compound ID', 'solubility', and 'soluble' columns as we do not want the model to use those to predict the solubility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature matrix (x) and target vector (y)\n",
    "X = df.drop(columns=['logS', 'smiles', 'mol', 'Compound ID', 'solubility', 'soluble'])\n",
    "y = df['logS']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle=True)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note</b>\n",
    "    Note the usage of <b>X</b> matrix instead of <b>x</b> vector in the <b>train_test_split</b> function, since now we want to use multiple features to predict the target variable.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting our data, we need to scale our training (and test) features. Scaling is a crucial step in the data preprocessing pipeline as it ensures that all features have the same scale as many machine learning models are sensitive to the scale of the input features. We will use the ``StandardScaler`` from the ``sklearn.preprocessing`` module to scale our features. Note that a Random Forest model does not require data scaling, as it is a tree-based model and so different scales will not affect model performance. We will still scale the data, however, so we can also build a linear regression model and compare the performance of two models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the standard scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training feature vector X_train\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test feature vector X_test\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Make sure the training data is scaled correctly\n",
    "print(f\" Training feature mean: {X_train_scaled.mean():.5f}\")\n",
    "print(f\" Training feature standard deviation: {x_train_scaled.std():.5f}\\n\")\n",
    "\n",
    "# Print the scaler statistics on the test data\n",
    "print(f\" Testing feature mean: {X_test_scaled.mean():.5f}\")\n",
    "print(f\" Testing feature standard deviation: {X_test_scaled.std():.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Reminder:</b>\n",
    "    It is extremely important to split the data first and then fit the scaler on the training data only. Fitting the scaler on the entire data and then splitting it can cause a <b>data leakage</b> problem which violates our intention to treat the test data as a good representative sample of the real-world data.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will build the multi-linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression model\n",
    "multi_feature_model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "multi_feature_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_linear_multi = multi_feature_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the performance metrics and store them in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred_linear_multi),     # the mean squared error\n",
    "    \"R2\": r2_score(y_test, y_pred_linear_multi)                 # the coefficient of determination\n",
    "}, index=[\"Multi-Linear-Regression\"])\n",
    "                            \n",
    "\n",
    "# Set the formatting style\n",
    "results.style.format(\n",
    "    {\n",
    "        \"MSE\": \"{:.3f}\",\n",
    "        \"R2\": \"{:.2f}\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h3>Discussion</h3>\n",
    "    Did model performance improve by using a multi-linear regression over the linear model?  What metrics indicate this?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Training a Random Forest Regression Model"
   ]
  },
  {
   "attachments": {
    "eca48c81-81c2-46d4-b5f1-ea524941698a.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a random forest model?\n",
    "There are many other kinds of machine learning models besides linear regression models.  One type is \n",
    "a random forest regression model. A random forest is a decision tree model that uses a \"forest\" of multiple decision trees and randomly chooses which variables to use in each tree. Generally, each individual tree is not that good at making a prediction, but collectively the trees are quite good at making predictions. Note that each tree predicts an individual value and then a vote is taken (in the case of regression, an average of the predicted values) to determine the final predicted value.\n",
    "\n",
    "![Random_forest_explain.png](attachment:eca48c81-81c2-46d4-b5f1-ea524941698a.png)\n",
    "\n",
    "### Hyperparameters\n",
    "Random forest models (and many other models) have hyperparameters that can be 'tuned' to opmitize model performance.The number of trees (``n_iterators``) can be specified, with a default value of 100 trees. Each tree also has a depth(``max_depth``) which specifies the maximum number of splits a tree can have, with the default value being no limit on the depth ('None'). Too few trees or trees that are too shallow results in a model that predicts poorly due to underfitting the data--the model is too simple to predict using train or test data. Too many trees or trees that are too deep results in a model that predicts poorly due to overfitting the data--the model is so complex it can predict using the original data extremely well but cannot predict using new data. The default values are a good starting place for most random forest models.\n",
    "\n",
    "### Building and training a default random forest regression model\n",
    "We will first build and train a random forest model that uses the default parameters. We will use the ``RandomForestRegressor`` class from the ``sklearn.ensemble`` module to create the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest regression model\n",
    "default_rf_reg_model = RandomForestRegressor()\n",
    "\n",
    "# Fit the model to the training data\n",
    "default_rf_reg_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_default_rf = default_rf_reg_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the performance metrics\n",
    "default_rf_reg_model_results = pd.DataFrame({\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred_default_rf),     # the mean squared error\n",
    "    \"R2\": r2_score(y_test, y_pred_default_rf)                 # the coefficient of determination\n",
    "}, index=[\"Default_RF_Regression\"])\n",
    "\n",
    "# Store the results into results DataFrame\n",
    "results = pd.concat([results, default_rf_reg_model_results])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h3>Discussion</h3>\n",
    "    Which model better at predicting the value of logS?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way to visualize model performance\n",
    "\n",
    "Now we will make plots again to visualize our model performance.  Another way you can do this is to plot your model performance vs. the original data.  If your model predicted every data point correctly, this would give a straight line, the line y=x.  You can look at the scatter compared to the y=x line and get a sense of how well your model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T16:52:00.069272Z",
     "start_time": "2024-06-26T16:51:59.817331Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a plot object\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Plot the test data\n",
    "ax.scatter(y_test, y_test, color='blue', label='Test Data')\n",
    "\n",
    "# Plot the simple linear regression model\n",
    "ax.scatter(y_test, y_pred_default_rf, color='red', label='Random Forest Regression')\n",
    "\n",
    "# Plot the multi-variable linear regression model\n",
    "ax.scatter(y_test, y_pred_linear_multi, color='green', label=\"Multifeature Linear Regression\")\n",
    "\n",
    "# Create the legends\n",
    "fig.legend(facecolor='white')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Training a Random Forest Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a classification model?\n",
    "Classification models predict classes rather than a range of values. Classification models are very popular in many situations because the predictions are easy to understand.  A model that take an image and predicts if it is a dog or a cat is a popular example of a classification model.\n",
    "\n",
    "For the data we have been working with, predicting if a compound is soluble or insoluble in water would be a relevant classification model. The model could predict \"insoluble\" versus \"soluble\", instead of predicting the numerical value of `logS`.  It is possible to build a multi-class classifier model with more than two classes, but these are more complex to build than a binary (two class) model. We will focus on a binary classification model.\n",
    "\n",
    "### Creating the binary target\n",
    "In order to predict a binary target, we need our data set to have a categorical variable as one of the features. This is a variable with only categories, or classes, even if those classes are represented as numbers. We added a column to our original dataframe called \"soluble\", one that labeled each molecule as either insoluble (0) or soluble (1). This will be the target variable for building our classification model. \n",
    "\n",
    "### Metrics for classification models\n",
    "We have been using RMSE and R2 values, but these are not useful for classification models. Instead we will use the ``sklearn.metrics`` functions for ``accuracy_score``, ``precision_score`` and ``recall_score``. \n",
    "\n",
    "<b>Accuracy</b> measures the correct predictions out of the total number of predictions. This is useful, but can be misleading if the data set has much more of one class over the other. For example, if toxic molecules are only 1% of an entire data set the accuracy would be 0.99 even if every toxic molecule was incorrectly classified as non-toxic. \n",
    "\n",
    "<b>Precision</b> measures how many negative values are falsely labeled as positive. This is an important metric if the cost of a false positive is high, for example incorrectly identifying a molecule as toxic and removing it from a list of potential drug candidates. \n",
    "\n",
    "<b>Recall</b> measures the ability to find all positives and is important when the cost of false negatives is high, for example predicting that a compound is non-toxic when it is actually toxic. \n",
    "\n",
    "Frequently all three metrics are evaluated for classification models. Note that precision and recall are often inversely related, and so you may need to find a compromise between the two when building a classification a model. There are many other ``sklearn.metrics`` for classification models, which you can explore on the scikitlearn website.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h3>Discussion</h3>\n",
    "    Is our dataset balanced (equal numbers in each class) for the <b>soluble</b> variable?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and training a default random forest classification model\n",
    " We will now build and train a random forest classification model that uses the default parameters. We will use \n",
    "the ``RandomForestClassifier`` class from the ``sklearn.ensemble`` module to create the model. We will also need to create new target  for the classification model, as the regression model utilized logS as the target variable. We will also need to do the train-test split again, as the previous split we were using a different target variable.  We will not generate the single-feature x vector as we will want to use more than one feature for our classification model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the training and testing data for the classification model\n",
    "\n",
    "# Create the feature matrix (X_clf) and the target vector (y_clf)\n",
    "X_clf = df.drop(columns=['Compound ID', 'smiles', 'logS','mol','solubility', 'soluble'])\n",
    "y_clf = df['soluble']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_clf_train, X_clf_test, y_clf_train, y_clf_test = train_test_split(X_clf, y_clf, test_size=0.2, random_state=123, shuffle=True)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "X_clf_train.shape, X_clf_test.shape, y_clf_train.shape, y_clf_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h3>Discussion</h3>\n",
    "    Why are we dropping the solubility and logS variables from the data used to train and test the classification model?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the classification data\n",
    "\n",
    "# Create the standard scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training feature matrix X_clf_train\n",
    "X_clf_train_scaled = scaler.fit_transform(X_clf_train)\n",
    "\n",
    "# Transform the test feature feature matrix X_clf_test\n",
    "X_clf_test_scaled = scaler.transform(X_clf_test)\n",
    "\n",
    "# Make sure the training data is scaled correctly\n",
    "print(f\" Training feature mean: {X_clf_train_scaled.mean():.5f}\")\n",
    "print(f\" Training feature standard deviation: {X_clf_train_scaled.std():.5f}\\n\")\n",
    "\n",
    "# Print the scaler statistics on the test data\n",
    "print(f\" Testing feature mean: {X_clf_test_scaled.mean():.5f}\")\n",
    "print(f\" Testing feature standard deviation: {X_clf_test_scaled.std():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classification model\n",
    "default_rf_clf_model = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "default_rf_clf_model.fit(X_clf_train_scaled, y_clf_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_default_rf_clf = default_rf_clf_model.predict(X_clf_test_scaled)\n",
    "\n",
    "# Calculate the performance metrics\n",
    "default_rf_clf_model_results = pd.DataFrame({\n",
    "    \"Accuracy\": accuracy_score(y_clf_test, y_pred_default_rf_clf),     # the accuracy score\n",
    "    \"Precision\": precision_score(y_clf_test, y_pred_default_rf_clf),   # the precision score\n",
    "    \"Recall\": recall_score(y_clf_test, y_pred_default_rf_clf)          # the recall score\n",
    "}, index=[\"Default_RF_Classifier\"])\n",
    "\n",
    "default_rf_clf_model_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h3>Discussion</h3>\n",
    "    Discuss how well the classification model performed. Were false positives an issue? False negatives? Your evaluation should be based on the metrics for model performance.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h3>Final Activity</h3>\n",
    "\n",
    "For our final activity, we will run the Random Forest classification model again but with new features of your choice. Look through the RDkit documentation and find <b>two</b> additional molecular properties you believe will be relevant for predicting solubility in water. Add these to the existing dataframe. \n",
    "\n",
    "Using the code above as a guide, train a new classification regression model using data that includes your new features.  You might also consider dropping some previous features.  \n",
    "\n",
    "To turn in today, prepare a short (less tha one page) lab report discussion your classification model.  What new features did you decide to add and/or delete compared to the original model?  Why did you think these models would be predictive of solubility?  Compare and contrast the performance of the original classification model with the model that utilized the two additional features.  Make sure you explain using the appropriate metrics.   \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Bonus material: Hyperparameter tuning (optional and outside of class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our  Random Forest models all used the default hyperparameter settings. Tuning (optimizing) hyperparameter settings can improve model performance. Code is provided for a loop to try a range of hyperparameter settings with our random forest models. Although we don't have time to use them today, tools such as ``GridSearchCV`` and ``Optuna`` can be used help identify the best set of hyperparameters. This is something you may want to consider for your class project. Read more about each hyperparameter on the scikitlearn website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the values to test for the n_iterators and max_depth hyperparameters\n",
    "trees = [50, 100, 300, 500, 1000]\n",
    "depths = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "## Defining lists to store results for each set of \n",
    "tree_count = []\n",
    "tree_depth = []\n",
    "tuned_rf_MSE = []\n",
    "tuned_rf_R2 = []\n",
    "\n",
    "for tree in trees:\n",
    "    \n",
    "    for depth in depths:\n",
    "        \n",
    "        # Create a random forest regression model\n",
    "        tuned_rf_model = RandomForestRegressor(n_estimators = tree, max_depth = depth)\n",
    "\n",
    "        # Fit the model to the training data\n",
    "        tuned_rf_model.fit(x_train_scaled, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred_tuned_rf = tuned_rf_model.predict(x_test_scaled)\n",
    "\n",
    "        # Storing the results in lists\n",
    "        tree_count.append(tree)\n",
    "        tree_depth.append(depth)\n",
    "        tuned_rf_MSE.append(mean_squared_error(y_test, y_pred_tuned_rf))\n",
    "        tuned_rf_R2.append(r2_score(y_test, y_pred_tuned_rf))\n",
    "        \n",
    "        \n",
    "# Create a DataFrame from the lists of results\n",
    "results_df = pd.DataFrame(\n",
    "    {'Number of trees': tree_count,\n",
    "     'Max depth': tree_depth,\n",
    "     'MSE': tuned_rf_MSE,\n",
    "     'R2': tuned_rf_R2\n",
    "    })\n",
    "\n",
    "# display the results DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
